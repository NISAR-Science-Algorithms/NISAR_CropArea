{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/60/NISAR_artist_concept.jpg\" width=400 align=\"left\"/><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9b/NISAR_Mission_Logo.png\" width=400 align=\"left\"/><br><br><br><br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# NASA ISRO Synthetic Aperture Radar Mission\n",
    "## Combined Algorithm Theoretical Basis Document and Jupyter Notebook for <br> *Active Crop Area*\n",
    "\n",
    "Authors: Shannon Rose, Tracy Whelen, Simon Kraatz, Paul Siqueira <br>\n",
    "Microwave Remote Sensing Laboratory <br>\n",
    "University of Massachusetts -- Amherst <br>\n",
    "Date: 2022-02-14 <br>\n",
    "\n",
    "\n",
    "### Summary\n",
    "This notebook describes the ATBD for generating an agricultural crop area product from NISAR time series data stacks. The algorithm is designed to meet the Level 2 Science requirements for detecting active crop area. This notebook constitutes a combination of formulating the theoretical basis for the NISAR active crop area algorithm that is based on the coefficient of variation and an implementation of the algorithm in executable python code. A test data set accompanies the notebook that can be downloaded at the same time as this notebook.  Should the reader have difficult accessing those resources, they are referred to [here](https://umass-my.sharepoint.com/:f:/g/personal/siqueira_umass_edu/EgRZPHq2VqZJtuWi1MvrJscByMsoVe9z8ESfkg8DdMnX-Q?e=K1wS3L).  This is a link to a OneDrive account at the University of Massachusetts.  The reader can download the *Crop_Area_Notebook.tgz*, which contains this notebook and the necessary files to run the code.\n",
    "\n",
    "This particular notebook contains two parts that are combined into one notebook.  These are\n",
    "<ol>\n",
    "    <li>The Coefficient of Variation (CV) Python code, and</li>\n",
    "    <li>The USDA Cropland Data Layer (CDL)</li>\n",
    "</ol>\n",
    "Although not required to implement the NISAR Active Crop Area algorithm, the CDL is provided here to give an example how external data about the location of active crops can be used to optimally determine the threshold that can be applied to the CV for determining active crop area, and also used as a means for evaluating the algorithm.  For regions outside of the US (for example) where the CDL is not available, a similar landcover classification could be used, or one created from available optical data.\n",
    "\n",
    "The NISAR requirement for Active Crop Area is <br>\n",
    "> *Requirement (L2-SCI-679):* <br> After the first year of operation, the NISAR Project shall measure crop area at 1-hectare resolution every 3 months with a classification accuracy of 80%.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id=\"TOC\"></a>\n",
    "### Table of Contents\n",
    "0.  [Getting Started](#SEC_0)\n",
    "    <br>0.1 [Overview of the Coefficient of Variation](#SEC_0.1)\n",
    "    <br>0.2 [Data Flow Diagram](#SEC_0.2)\n",
    "    <br>0.3 [Import Python Modules (code)](#SEC_0.3)\n",
    "    <br>0.4 [Set the Input Parameters (code)](#SEC_0.4)\n",
    "    <br>0.5 [Set the Output Parameters (code)](#SEC_0.5)\n",
    "1. [Get Data](#SEC_1)\n",
    "    <br>1.1  [Pre-Launch: Get GCOV data from S3 Buckets](#SEC_1.1)\n",
    "    <br>1.2  [Post-Launch: Query EarthData using earthaccess for GCOV data](#SEC_1.2)\n",
    "    <br>1.3  [Post-Launch: Query ASF using asf_search for GCOV data](#SEC_1.3)\n",
    "    <br>1.4  [Select Images to Include in Time-Series Stack](#SEC_1.4)\n",
    "    <br>1.4  [Get Geocoding Information from First/Reference Images](#SEC_1.4)\n",
    "2. [CDL Preparation](#SEC_2)\n",
    "    <br>2.1  [Download the CDL](#SEC_2.1)\n",
    "    <br>2.2  [Sample image of the Cropland Data Layer](#SEC_2.2)\n",
    "    <br>2.3  [A simple Crop-/Non-Crop mask](#SEC_2.3)\n",
    "    <br>2.4  [Identifying Crop pixels in the CDL](#SEC_2.4)\n",
    "    <br>2.5  [Image of the Crop/Non-Crop classification based on the CDL](#SEC_2.5)\n",
    "    <br>2.6  [A statistical summary of the number of Crop and Non-Crop pixels from the CDL](#SEC_2.6)\n",
    "3.  [Time-Series analysis of SAR images](#SEC_3)\n",
    "    <br>3.1  [Read in Imagery](#SEC_3.1)\n",
    "    <br>3.2  [Sample SAR images](#SEC_3.2)\n",
    "    <br>3.3  [Calculating the CV on the Timeseries Stack](#SEC_3.3)\n",
    "4.  [Generation of the Receiver Operating Characteristic](#SEC_4)\n",
    "    <br>4.1  [Applying thrsholds to determine the ROC](#SEC_4.1)\n",
    "    <br>4.2  [Apply the watermask to each tested point](#SEC_4.2)\n",
    "    <br>4.3  [Create a binary crop/non-crop classification at each tested threshold](#SEC_4.3)\n",
    "    <br>4.4  [Determine false alarm and true positive rates](#SEC_4.4)\n",
    "    <br>4.5  [Calculate sensitivity and specifity](#SEC_4.5)\n",
    "    <br>4.6  [Calculate the ROC Curve](#SEC_4.6)\n",
    "    <br>4.7  [Plot the ROC Curve](#SEC_4.7)\n",
    "5.  [Calculate optimal threshold and other performance metrics](#SEC_5)\n",
    "    <br>5.1  [Using Youden's Index to Find the Ideal Classification Threshold](#SEC_5.1)\n",
    "    <br>5.2  [Display Youden's index](#SEC_5.2)\n",
    "    <br>5.3  [Find the AUC](#SEC_5.3)\n",
    "    <br>5.4  [Getting Accuracy Statictics for the Youden's Index Optimal Threshold](#SEC_5.4)\n",
    "    <br>5.5  [Export Accuracy Results](#SEC_5.5)\n",
    "    <br>5.6  [Export Classified Image](#SEC_5.6)\n",
    "\n",
    "6. [References](#SEC_6)\n",
    "\n",
    "[back to TOP](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_0\"></a>\n",
    "<a id=\"SEC_0.1\"></a>\n",
    "# 0  &emsp; Getting Started\n",
    "## 0.1 &emsp; Overview of the Coefficient of Variation\n",
    "Python code to implement coefficient of variation (CV) for crop/non-crop classification using a Receiver Operating Characteristic (ROC) curve for a time-series of SAR images. The notebook statistically calculates the CV for a stack of time-series imagery. The CV output is then used to generate a ROC curve by using the USDA Cropland Data Layer (CDL) as ground truth. Pixels classified by the CDL as \"Water\" are masked and not used in classification because, water has a high variation measurement not comparable to the CV values of other non-cropland land covers and is often missclassified because of this. The statistic Youden's Index is calculated to detemine the ideal threshold on the curve to use for best classification results. The accuracy of the classification compared to the CDL as ground truth are calculated for the CV crop/non-crop classification. The classified image is exported as a Geotiff. A CSV file is exported containing accuracy statistics for the classification.\n",
    "\n",
    "Coefficient of Variation is calculated by: Standard Deviation/Mean\n",
    "\n",
    "Datasets needed:\n",
    "\n",
    "    Timeseries of SAR imagery\n",
    "    \n",
    "    CDL available at https://nassgeodata.gmu.edu/CropScape/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_0.2\"></a>\n",
    "## 0.2  &emsp; Data Flow Diagram\n",
    "\n",
    "![data_flow_diagram](CV_ROC_Data_Flow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_0.3\"></a>\n",
    "## 0.3 &emsp; Import Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal, osr, ogr\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pandas import DataFrame\n",
    "from IPython.display import Image\n",
    "import sklearn  # imported from scikit-learn\n",
    "from sklearn import metrics\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ipywidgets import interactive\n",
    "from rasterio.plot import show_hist\n",
    "import datetime\n",
    "from datetime import date\n",
    "os.environ['GDAL_DATA']= os.popen('gdal-config --datadir').read().rstrip() #resolves gdal directory value error \n",
    "import math\n",
    "\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import rasterio\n",
    "import zipfile\n",
    "import h5py\n",
    "from pyproj import CRS\n",
    "import earthaccess\n",
    "import geopandas as gpd\n",
    "import copy\n",
    "import asf_search as asf\n",
    "import json\n",
    "from getpass import getpass\n",
    "import s3fs\n",
    "import psycopg2\n",
    "import getpass\n",
    "import configparser\n",
    "from psycopg2 import sql\n",
    "import requests\n",
    "import s3fs\n",
    "\n",
    "import earthaccess\n",
    "import asf_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_0.4\"></a>\n",
    "## 0.4 &emsp; Set the Input Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "    1. For use in this notebook all raster datasets must be set to the same grid with pixels aligned\n",
    "    2. The only data that can be in the set \"inputs\" is the timeseries SAR imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_dir= Path(os.getcwd()).resolve().parents[0]\n",
    "ancillary_dir= main_dir/ 'ancillary_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What site? Little_River_GA\n"
     ]
    }
   ],
   "source": [
    "aoi= input('What site?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Little_River_GA\n",
      "/home/jovyan/Little_River_GA/crops\n"
     ]
    }
   ],
   "source": [
    "aoi_dir = main_dir / aoi \n",
    "crop_dir = aoi_dir / 'crops'\n",
    "print(aoi_dir)\n",
    "\n",
    "GCOV_dir = aoi_dir / '47'/'620'/'GCOV'\n",
    "TMP_dir = aoi_dir / 'TMP'\n",
    "\n",
    "Path(aoi_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(crop_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(GCOV_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(TMP_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bucket_name = \"nisar-st-data-ondemand\" #fill in S3_bucket name\n",
    "s3_path = 'ALOS2_processed/%s/' %(aoi)\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "print(crop_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What polarization? [HH or HV]: HH\n"
     ]
    }
   ],
   "source": [
    "which_pol= input('What polarization? [HH or HV]:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_0.5\"></a>\n",
    "## 0.5 &emsp; Get extent from a geojson file specifing the Area of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32617\n",
      "POLYGON Z ((-83.504091 31.463803 0, -83.786121 31.463885 0, -83.786456 31.76044 0, -83.504147 31.759516 0, -83.504091 31.463803 0))\n"
     ]
    }
   ],
   "source": [
    "#ds= gpd.read_file(aoi_dir/('%s.geojson' %(aoi)))\n",
    "ds= gpd.read_file('/home/jovyan/tifton.geojson')\n",
    "\n",
    "## Get Lat/Lon coordinates (Earthdata search must be in lat/lon)\n",
    "box_left, box_top, box_right, box_bottom = ds.geometry[0].bounds\n",
    "x1,y1,x2,y2 = math.floor(box_left),math.floor(box_top),math.floor(box_right),math.floor(box_bottom)\n",
    "zone = int(np.ceil((box_left + 180)/6))\n",
    "\n",
    "if y1>=0:\n",
    "    EPSG = 32600+zone\n",
    "elif y1<0:\n",
    "    EPSG = 32600+zone\n",
    "print(EPSG)\n",
    "x_posting = 20 ## choose posting\n",
    "y_posting = 20 ## choose posting\n",
    "wkt = ds.geometry[0].wkt\n",
    "print(wkt)\n",
    "\n",
    "## Get UTM coordinates (GCOV products will be in UTM)\n",
    "ds = ds.to_crs(EPSG)\n",
    "minx, miny, maxx, maxy = ds.geometry[0].bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"SEC_1\"></a>\n",
    "# 1 &emsp; Get Data\n",
    "#### note: an example time series of NISAR simulated data for Tifton, GA is provided in the ProductGeneration gitlab Repo. Querying ASF and EarthAccess for NISAR data will be accessible post launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_1.1\"></a>\n",
    "# 1.1  &emsp; Pre-Launch: Get GCOV Data from local directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What data source are you getting data from? [example GCOV stack or ASF search or earthaccess?]: ASF search\n"
     ]
    }
   ],
   "source": [
    "get_data= input('What data source are you getting data from? [example GCOV stack or ASF search or earthaccess?]:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if get_data=='example GCOV stack':\n",
    "    all_GCOV_data= sorted(glob.glob(str(GCOV_dir/'NISAR_L2_PR_GCOV_*_cropped.tif')))\n",
    "    for i in range(len(all_GCOV_data)):\n",
    "        print( i, all_GCOV_data[i].split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_1.2\"></a>\n",
    "# 1.2  &emsp; Post-Launch: Query EarthData using **earthaccess** for GCOV Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_data=='earthaccess':\n",
    "    auth= earthaccess.login()\n",
    "\n",
    "    results = earthaccess.search_data(short_name = 'NISAR_L2_GCOV_BETA_V1', \n",
    "                                        # temporal = ('2023-07-01 00:00:00', '2023-08-31 23:59:59'), # can also specify by time\n",
    "                                        # granule_name = '*T00888*', # here we filter by files with CRID value of *T00888*\n",
    "                                        bounding_box = (box_left, box_top, box_right, box_bottom )\n",
    "                                       )\n",
    "    ## Get S3 URLS for search results\n",
    "    all_GCOV_data = [earthaccess.results.DataGranule.data_links(x, access='direct')[0] for x in results if earthaccess.results.DataGranule.data_links(x, access='direct')[0].endswith('.h5')]\n",
    "\n",
    "    print(\"number of available scenes:\", len(all_GCOV_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_files = earthaccess.download(nisar_results, GCOV_dir) \n",
    "# del download_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_1.3\"></a>\n",
    "# 1.3  &emsp; Post-Launch: Query ASF using **asf_search** for GCOV Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`aws credentials{id: ABIAS9L8MS5IPHTZPPUQ secret: .v2QPKHl7LcdVYsjaR4LgQiZ1zw3MAnMyiondXC63;}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_data=='ASF search':\n",
    "    Session= asf.ASFSession()\n",
    "    Session.auth_with_creds(getpass.getpass('username'),getpass.getpass('password'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_data== 'ASF search':\n",
    "    opts = asf.ASFSearchOptions(dataset=asf.DATASET.NISAR,\n",
    "                            # processingLevel=asf.PRODUCT_TYPE.GCOV,\n",
    "                            session=Session, \n",
    "                            # maxResults = 10,\n",
    "                            )\n",
    "    results = asf.geo_search(intersectsWith = wkt, opts=opts)\n",
    "    \n",
    "    ## Get S3 URLS for search results\n",
    "    all_GCOV_data = [x['properties']['s3Urls'][y] for x in results.geojson()['features'] for y in range(len(x['properties']['s3Urls'])) if x['properties']['s3Urls'][y].endswith('.h5') ]\n",
    "\n",
    "    print('There are %s results' %(len(all_GCOV_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_1.4\"></a>\n",
    "# 1.4  &emsp; Select Images to Include in Time-Series Stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices= input('which GCOV files should be used? ex: 0-1, 0, 1, 5, 1:5 inclusive')\n",
    "if ':' in indices:\n",
    "    indices2 = list(range(int(indices.split(':')[0]), int(indices.split(':')[1])+1))\n",
    "\n",
    "elif '-' in indices:\n",
    "    indices2 = list(range(int(indices.split('-')[0]), int(indices.split('-')[1])+1))\n",
    "elif ',' in indices:\n",
    "    indices2 = []\n",
    "    num = indices.split(',')\n",
    "    for n in range(0,len(num)):\n",
    "        indices2.append(int(num[n]))\n",
    "else:\n",
    "    print('index type not recognized, please rerun the cell')\n",
    "        \n",
    "\n",
    "## If you don't want to use all of the images, choose which indices to use now. \n",
    "# indices = range(0,19)\n",
    "print(indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dates of observation (HH and HV):\")\n",
    "date_array = []\n",
    "SAR_images = []\n",
    "for ii in indices2:\n",
    "    datestr = all_GCOV_data[ii].split('/')[-1].split('_')[11]\n",
    "    date_obj= pd.to_datetime(datestr)\n",
    "    print(date_obj)\n",
    "    date_array.append(date_obj)\n",
    "    SAR_images.append(all_GCOV_data[ii])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#<a id=\"SEC_1.5\"></a>\n",
    "## 1.5  &emsp; Get Geocoding Information from First/Reference Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_data== \"example GCOV stack\":\n",
    "    first_raster = gdal.Open(SAR_images[1])\n",
    "    rows = first_raster.RasterYSize\n",
    "    cols = first_raster.RasterXSize\n",
    "    geotransform = first_raster.GetGeoTransform()\n",
    "    xres = geotransform[1]\n",
    "    yres = -geotransform[5]\n",
    "    xmin = geotransform[0]\n",
    "    ymax = geotransform[3]\n",
    "    spatialref = first_raster.GetProjectionRef()\n",
    "\n",
    "print(rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_data == \"earthaccess\" or get_data == \"ASF search\":\n",
    "    s3cred = requests.get(\"https://nisar.asf.earthdatacloud.nasa.gov/s3credentials\").json()\n",
    "    s3 = s3fs.S3FileSystem(anon=False, key=s3cred['accessKeyId'], \n",
    "                   secret=s3cred['secretAccessKey'],\n",
    "                   token = s3cred['sessionToken'],\n",
    "                   client_kwargs={'region_name': 'us-west-2'})\n",
    "\n",
    "    ref_image= SAR_images[0]\n",
    "    f = h5py.File(s3.open(ref_image, \"rb\"), \"r\") \n",
    "    a_group_key = list(f.keys())[0]\n",
    "    ds_x = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['xCoordinates'][()]      # returns as a h5py dataset object\n",
    "    ds_y = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['yCoordinates'][()]      # returns as a h5py dataset object\n",
    "    ds_epsg = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['projection'][()]\n",
    "    mask = np.where(np.isnan(f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['HHHH'][()]),np.nan,1)\n",
    "\n",
    "    cols = ds_x.shape[0]\n",
    "    rows = ds_y.shape[0]\n",
    "    print('X Size: ',cols,' Y Size: ',rows)\n",
    "\n",
    "    yres = abs(ds_y[0] - ds_y[1])\n",
    "    xres = abs(ds_x[0] - ds_x[1])\n",
    "    print('Resolution X:', xres, ' Y:',yres,'m')\n",
    "\n",
    "    ulx = ds_x[0] - ((ds_x[1] - ds_x[0])/2)\n",
    "    lrx = ds_x[-1] + ((ds_x[1] - ds_x[0])/2)\n",
    "    uly = ds_y[0] - ((ds_y[1] - ds_y[0])/2)\n",
    "    lry = ds_y[-1]+ ((ds_y[1] - ds_y[0])/2)\n",
    "\n",
    "    print('Raster bounds: ',ulx,lrx,uly,lry)#min(ds_x),max(ds_x),min(ds_y),max(ds_y))\n",
    "    geotransform = [ulx, xres, 0.0, uly, 0.0, -yres]\n",
    "\n",
    "    spatialref = CRS.from_user_input(EPSG).to_wkt()\n",
    "    print(ds_epsg)\n",
    "\n",
    "\n",
    "    del ds_y, ds_x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_2\"></a>\n",
    "# 2 &emsp; CDL Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_2.1\"></a>\n",
    "## 2.1 &emsp; Download the Cropland Data Layer\n",
    "\n",
    "Having access to the Cropland Data Layer ([CDL](https://nassgeodata.gmu.edu/CropScape/); a landcover classification for the continental US) is not required for the Coefficient of Variation algorithm, it can be used as an input to determine the location of crops versus non-crops, and hence used to determine the best threshold for the NISAR Active Crop Area algorithm.  In locations where the CDL is not available, other products may be available (such as ESA's [GlobCover](http://due.esrin.esa.int/page_globcover.php) and [High Resolution Ground Cover](https://climate.esa.int/en/projects/high-resolution-land-cover/)), or derived independently from available high-resolution optical data.\n",
    "\n",
    "The data provided as part of this NISAR ATDB Notebook has been extracted from the CDL and provided locally so that the notebook can be self-contained and it is not necessary to download those resources to exercise the NISAR Active Crop Area algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the CDL colormap (an index of color values) and identify it as a colormap\n",
    "# CDL = glob.glob(str(aoi_inputs/'CDL*.tif'))[0]\n",
    "\n",
    "cdl_cmap = np.loadtxt(ancillary_dir / 'cdl_cmap.txt',dtype='float')\n",
    "cdl_cmap = ListedColormap(cdl_cmap)\n",
    "\n",
    "cdl_year = 2022\n",
    "cdl_dir = ancillary_dir / 'cdl'\n",
    "cdl_full_file = '%s_30m_cdls' %(cdl_year)\n",
    "\n",
    "if os.path.isfile(cdl_dir/ (cdl_full_file +'.tif'))==False:\n",
    "    if os.path.isfile(cdl_dir / (cdl_full_file + '.zip'))==False:\n",
    "        url = 'https://www.nass.usda.gov/Research_and_Science/Cropland/Release/datasets/%s.zip' %(cdl_full_file)\n",
    "        !wget -P {cdl_dir} -q {'https://www.nass.usda.gov/Research_and_Science/Cropland/Release/datasets/2022_30m_cdls.zip'}\n",
    "    with zipfile.ZipFile(cdl_dir / (cdl_full_file + '.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall(cdl_dir)\n",
    "    os.remove(cdl_dir/ (cdl_full_file + '.zip'))\n",
    "CDL_full = glob.glob(str(cdl_dir / (cdl_full_file + '.tif')))[0]\n",
    "cdl_crop_file= '%s_CDL_%s.tif' %(aoi, cdl_year)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract/Crop CDL raster to reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('gdalwarp -overwrite -s_srs epsg:5070 -t_srs epsg:%s -tap -tr %s %s -te %s %s %s %s %s %s' \n",
    "          %(EPSG,x_posting,y_posting,minx,miny,maxx,maxy,CDL_full,crop_dir/cdl_crop_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dimensions of CDL\n",
    "first_raster_CDL = gdal.Open(str(crop_dir / (aoi + '_CDL_2022.tif')))\n",
    "rows1 = first_raster_CDL.RasterYSize\n",
    "cols1 = first_raster_CDL.RasterXSize\n",
    "\n",
    "\n",
    "# Open CDL\n",
    "cdl_raster = first_raster_CDL.ReadAsArray()#*mask\n",
    "print(cdl_raster.shape)\n",
    "\n",
    "CDL_geotransform = first_raster_CDL.GetGeoTransform()\n",
    "CDL_xres = CDL_geotransform[1]\n",
    "CDL_yres = -CDL_geotransform[5]\n",
    "CDL_xmin = CDL_geotransform[0]\n",
    "CDL_ymax = CDL_geotransform[3]\n",
    "CDL_spatialref = first_raster_CDL.GetProjectionRef()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20,5);\n",
    "plt.imshow(cdl_raster,cmap=cdl_cmap,interpolation='nearest');\n",
    "plt.colorbar(fraction=0.046*cdl_raster.shape[0]/cdl_raster.shape[1],pad=0.04);\n",
    "plt.title('Cropland Data Layer');\n",
    "\n",
    "del first_raster_CDL\n",
    "##The image might look a little busy because of the number of classes in the layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_2.2\"></a>\n",
    "## 2.2 &emsp; Sample image of the Cropland Data Layer\n",
    "Creating a mask to not include pixels in the CDL classified as \"Water\".\n",
    "Water has a high variation measurement not comparable to the CV values of other non-cropland land covers and is often missclassified because of this.\n",
    "\n",
    "The numeric classification value of \"Water\" in the CDL is 111.\n",
    "The mask sets water (111 values) to 111 and everything else to 0.\n",
    "\n",
    "Note: Additional masking can be completed outside of this notebook by classifying these areas in the CDL as 111 for use in this         notebook.\n",
    "   Some pervious factors that were masked during classification to eliminate errors inherently present in the CDL:\n",
    "       1. Pixels that are not surrounded by their same land cover type \n",
    "       2. Classified land areas smaller than two hectares in size\n",
    "\n",
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_2.3\"></a>\n",
    "## 2.3 &emsp; A simple Crop/Non-Crop mask\n",
    "In creating a Crop/Non-Crop mask from the Cropland Data Layer, the first step is to identify all of those pixels that are makred as \"water\" (index value 111 in the CDL).  The water pixels in the CDL encompass not only water pixels, but often other types of infrastructure (e.g. roads) that has a similar signature in the optical image time-series that is used for generating the CDL.  A water mask for the Coefficient of Variation algorithm is important because water will have a confounding signature in radar similar to that of crops.\n",
    "\n",
    "The image below shows those pixels of the CDL that are marked as water, with red being everything else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_number = 111\n",
    "watermask1 = cdl_raster == water_number\n",
    "watermask= np.multiply(cdl_raster,watermask1)\n",
    "\n",
    "# Get the number of pixels masked and not masked \n",
    "cdl111 = np.count_nonzero(watermask == water_number) \n",
    "print(\"Number of water pixels:\", cdl111)\n",
    "\n",
    "cdl0 = np.count_nonzero(watermask == 0)\n",
    "print(\"Number of pixels for classification:\", cdl0)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20,5)\n",
    "plt.imshow(watermask,interpolation='nearest')\n",
    "plt.set_cmap('Reds_r')\n",
    "# For more colormaps, see: https://gallantlab.github.io/colormaps.html\n",
    "plt.colorbar();\n",
    "print('water pixels are marked as white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_2.4\"></a>\n",
    "## 2.4 &emsp; Identifying Crop pixels in the CDL\n",
    "\n",
    "Creating a binary crop/non-crop classification from the CDL classified classes.\n",
    "\n",
    "Crop classified to 1\n",
    "\n",
    "Non-crop classified to 0\n",
    "\n",
    "This can be customized by study area and what land use types are present there. \n",
    "To make a land class classified as non-crop simply place a \"#\" infront of the line of code for that land cover.\n",
    "\n",
    "In the code that follows, these are assigned one-by-one according the to various index indicators that are part of the CDL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDL_crop = np.copy(cdl_raster)\n",
    "unique = np.unique(cdl_raster)\n",
    "uniquecount = len(unique)\n",
    "\n",
    "# Get Crop names and ids\n",
    "# Column 0 = Crop ID\n",
    "# Column 1 = Crop Name\n",
    "# Column 2 = Classification number (1 = crop 0 = not crop)\n",
    "\n",
    "crop_ids = pd.read_csv(ancillary_dir / 'crop_ids.csv',header=None)\n",
    "# Set all crop classification values equal to 1 \n",
    "for i in crop_ids[0]:\n",
    "    CDL_crop[np.where(cdl_raster==i)] = crop_ids[crop_ids[0]==i][2]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_2.5\"></a>\n",
    "## 2.5 &emsp; Image of the Crop/Non-Crop classification based on the CDL\n",
    "Below is the resulting clasification image of Crop versus Non-Crop based on the input Cropland Data Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all non-crop values to 0 based on assumming that everything not previously classified as crop is non-crop\n",
    "CDL_binary = np.copy(CDL_crop)\n",
    "CDL_binary[np.where(CDL_crop!= 1)]= 0\n",
    "CDL_binary = CDL_binary#*mask\n",
    "plt.imshow(CDL_binary,interpolation='nearest')\n",
    "plt.colorbar();\n",
    "print('Crop pixels marked as white (value of 1.0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_2.6\"></a>\n",
    "## 2.6 &emsp; A statistical summary of the number of Crop and Non-Crop pixels from the CDL\n",
    "\n",
    "Finding the breakdown of crop/non-crop pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the number of pixels classified as crop and non-crop including the removal of masked pixels\n",
    "cropcount = np.count_nonzero(CDL_binary == 1)\n",
    "print(\"Number of crop pixels:\", cropcount)\n",
    "\n",
    "noncount = np.count_nonzero(CDL_binary == 0)- cdl111\n",
    "print(\"Number of non-crop pixels:\",noncount)\n",
    "\n",
    "#finding the percent of pixels classified as crop and non-crop including the removal of masked pixels\n",
    "percent_crop_nonmasked_calc = round((cropcount / cdl0)*100, 2)\n",
    "print (\"% Crop: \", percent_crop_nonmasked_calc)\n",
    "\n",
    "percent_noncrop_nonmasked_calc = round((noncount / cdl0)*100, 2)\n",
    "print (\"% Non-crop: \", percent_noncrop_nonmasked_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_3\"></a>\n",
    "# 3   &emsp;  Time-Series Analysis of SAR Images\n",
    "\n",
    "Creates a time-series stack of the SAR imagery\n",
    "\n",
    "The time-series of SAR images is nominally meant to be downloaded from an instrument data archive.  Here, we utilizea time-series of Sentinel-1 images that have already been downloaded and co-registered for the area of interest.  Sentinel-1 time-series was chosen for this example because of the basic availability of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_3.1\"></a>\n",
    "## 3.1   &emsp;  Read in Imagery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Launch: Read in example time series stack provided in repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if get_data  == \"example GCOV stack\":\n",
    "    #SAR_image_folder= Path('/home/jovyan/ProductGeneration/notebooks/tifton/')\n",
    "    ds_HH = glob.glob(str(GCOV_dir/'*HHHH_cropped.tif'))\n",
    "    ds_HV= glob.glob(str(GCOV_dir/'*HVHV_cropped.tif'))\n",
    "    arrs_HH= []\n",
    "    arrs_HV= []\n",
    "\n",
    "    for image in ds_HH:\n",
    "        print(os.path.split(image)[-1])\n",
    "        arrs_HH.append(gdal.Open(image).ReadAsArray())\n",
    "    for image in ds_HV:\n",
    "        print(os.path.split(image)[-1])\n",
    "        arrs_HV.append(gdal.Open(image).ReadAsArray())\n",
    "    \n",
    "    a_HH= np.array(arrs_HH, dtype=float)\n",
    "    a_HV= np.array(arrs_HV, dtype= float)\n",
    "    num_dates= len(arrs_HH)\n",
    "    print(\"\\nNumber of dates in time series analysis:\", num_dates)\n",
    "\n",
    "    del arrs_HH\n",
    "    del arrs_HV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Launch: Read in time series stack from ASF or earth access query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_data == \"earthaccess\" or get_data == \"ASF search\":\n",
    "    # Read raster files and make them into a 3D numpy array\n",
    "    arrs_HH = []\n",
    "    arrs_HV = []\n",
    "\n",
    "    for image in SAR_images:\n",
    "        print(os.path.split(image)[-1])  \n",
    "        f = h5py.File(image, \"r\") \n",
    "        a_group_key = list(f.keys())[0]\n",
    "        ds_HH = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['HHHH'][()] \n",
    "        ds_HV = f[a_group_key]['LSAR']['GCOV']['grids']['frequencyA']['HVHV'][()] \n",
    "        if (ds_HH.shape[1] == cols) & (ds_HH.shape[0] == rows):\n",
    "            arrs_HV.append(ds_HV)\n",
    "            arrs_HH.append(ds_HH)\n",
    "        else:\n",
    "            print('Dimensions of this SAR image do not match the reference image, SKIP')\n",
    "\n",
    "            del ds_HH, ds_HV, f\n",
    "\n",
    "    a_HH = np.array(arrs_HH, dtype=float)\n",
    "    a_HV = np.array(arrs_HV, dtype=float)\n",
    "\n",
    "    # Creating a variable for the number of images (one for each date)\n",
    "    num_dates = len(arrs_HH)\n",
    "    print (\"\\nNumber of dates used in time series analysis:\", num_dates)\n",
    "\n",
    "    xmin = ulx\n",
    "    ymax = uly\n",
    "\n",
    "    del arrs_HV, arrs_HH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot sample SAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = plt.get_cmap('Greys_r')\n",
    "plt.rcParams['figure.figsize'] = (20,8)\n",
    "for i in range(0,min(4,len(a_HH))):\n",
    "    ax = plt.subplot(2,2,i+1)\n",
    "    plt.imshow(10*np.log10(a_HH[i,:,:]),vmin=-22,vmax=-5,interpolation='nearest',cmap=cmp)\n",
    "    plt.colorbar(label = 'dB')\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    ax.axes.get_yaxis().set_ticks([])\n",
    "    plt.title(date_array[i],fontsize=8) ## This will change once we rename the files to NISAR format\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_3.2\"></a>\n",
    "## 3.2 &emsp; Calculating the CV on the Timeseries Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation for the Coefficient of Variation (CV) is:\n",
    "\n",
    "CV = Standard Deviation / Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean for the time stack of images\n",
    "mean_HH = np.mean(a_HH, axis = 0)\n",
    "mean_HV = np.mean(a_HV, axis = 0)\n",
    "\n",
    "\n",
    "# Calculate the standard deviation for the time stack of images\n",
    "std_HH = np.std(a_HH, axis = 0)\n",
    "std_HV = np.std(a_HV, axis = 0)\n",
    "\n",
    "# Calculate the coefficient of variation for the time stack of images \n",
    "CV_HH = (std_HH/mean_HH)#*mask\n",
    "CV_HV = (std_HV/mean_HV)#*mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,[ax,ax2] = plt.subplots(1,2,figsize=(20,5))\n",
    "im=ax.imshow(10*np.log10(mean_HH),vmin=-22,vmax=-10,interpolation='nearest',cmap=cmp);\n",
    "im2=ax2.imshow(10*np.log10(mean_HV),vmin=-22,vmax=-10,interpolation='nearest',cmap=cmp);\n",
    "plt.colorbar(im,ax=ax,fraction=0.046*mean_HH.shape[0]/mean_HH.shape[1],pad=0.04,label='HH db'); ##originally labeled as linear, but title and math are db\n",
    "plt.colorbar(im2,ax=ax2,fraction=0.046*mean_HH.shape[0]/mean_HH.shape[1],pad=0.04,label='HV db');\n",
    "plt.suptitle('Mean Radar-Cross Section (dB)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Values in dB')\n",
    "print(\"HH Pixel Standard Deviation: Min = %s, Max = %s, Mean = %s\" %(round(np.nanmin(std_HH),6),round(np.nanmax(std_HH),6),round(np.nanmean(std_HH),6)))\n",
    "print(\"HH Pixel Coefficient of Variation: Min = %s, Max = %s, Mean = %s\" %(round(np.nanmin(CV_HH),6),round(np.nanmax(CV_HH),6),round(np.nanmean(CV_HH),6)))\n",
    "\n",
    "show_hist(np.clip(CV_HH,0,1),bins=50,title=\"Histogram of HH CV values\")  # this is the only routine that uses rasterio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Values in dB')\n",
    "print(\"HV Pixel Standard Deviation: Min = %s, Max = %s, Mean = %s\" %(round(np.nanmin(std_HV),6),round(np.nanmax(std_HV),6),round(np.nanmean(std_HV),6)))\n",
    "print(\"HV Pixel Coefficient of Variation: Min = %s, Max = %s, Mean = %s\" %(round(np.nanmin(CV_HV),6),round(np.nanmax(CV_HV),6),round(np.nanmean(CV_HV),6)))\n",
    "\n",
    "show_hist(np.clip(CV_HV,0,1),bins=50,title=\"Histogram of HV CV values\")  # this is the only routine that uses rasterio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,[ax,ax2] = plt.subplots(1,2)\n",
    "im = ax.imshow(std_HH,vmin=0,vmax=0.02,interpolation='nearest',cmap=cmp);\n",
    "plt.colorbar(im,ax=ax,fraction=0.046*(rows/cols),pad=0.04,label='HH dB');\n",
    "im2 = ax2.imshow(std_HV,vmin=0,vmax=0.02,interpolation='nearest',cmap=cmp);\n",
    "plt.colorbar(im,ax=ax2,fraction=0.046*(rows/cols),pad=0.04,label='HV dB');\n",
    "plt.suptitle('Standard deviation of Radar Cross Section (magnitude)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,[ax,ax2] = plt.subplots(1,2)\n",
    "im = ax.imshow(CV_HH,vmin=0.05,vmax=1,interpolation='nearest',cmap='Reds');\n",
    "plt.colorbar(im, ax=ax, fraction=0.046*CV_HH.shape[0]/CV_HH.shape[1],pad=0.04,label=' HH dB ');\n",
    "im2 = ax2.imshow(CV_HV,vmin=0.05,vmax=1,interpolation='nearest',cmap='Reds');\n",
    "plt.colorbar(im2, ax=ax2, fraction=0.046*CV_HH.shape[0]/CV_HV.shape[1],pad=0.04,label='HV dB');\n",
    "plt.suptitle('Coefficient of Variation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del std_HH, a_HH, mean_HH, std_HV, a_HV, mean_HV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_4\"></a>\n",
    "# 4 &emsp; Generation of the Receiver Operating Characteristic\n",
    "The Receiver Operating Characteristic ([ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)) is a well-known graphical analysis device that can be used for evaluating the choice of thresholds in a binary classification.  It is a plot of the False Positive (a.k.a. False Alarm Rate) versus the True Positive rates in a standard hypothesis test.  Graphical limits of the ROC for the horizontal and vertical axes are between zero and one, indicating ranges of zero probability up to a probability of one.\n",
    "\n",
    "Curves in the ROC represent a choice of thresholds of the discriminating variable, in this case, the Coefficient of Variation (CV) that has been derived in the previous section.  Using the Crop/Non-crop map derived from the CDL, the CV derived from a SAR time-series, thresholds can be implemented value-by-value to create a locus of points that create a curve in the ROC space.  A diagonal line with a slope of one in the ROC indicates an arbitrary choice.  As the ability of the discriminating metric improves, the loci of points will tend towards the upper left-hand corner (ULC) of the ROC.  The upper left-hand corner of the ROC indicates a False Alarm rate of zero, and a True positive rate of unity.  The threshold that is furthest away from the diagonal line representing arbitrary choice, and closest to the ULC can be considered the optimal choice for the Crop/Non-Crop hypothesis test.\n",
    "\n",
    "In what follows is a systematic method for generating this locus of points that uses the Coefficient of Variation for the Crop/Non-Crop classifier based on the SAR time-series.  In the absence of a ground-validation component such as the Crop/Non-Crop input from the CDL, the choice of threshold can be determined from previous analysis that has been performed for the optimum CV threshold.  For Sentinel-1 C-band data, this optimum CV threshold is in the range of 0.3 - 0.5.  For L-band data, the optimal threshold of CV value ranges from 0.4 - 0.5.  Using the CDL as an input, a spatial dependence of the CV values has been studied within the US and can be found [here](#SEC_5).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_4.1\"></a>\n",
    "## 4.1 &emsp; Applying thresholds to determine the ROC\n",
    "To create the curve 100 different sensitivity points ranging between 0 and 1 in steps of 0.1 were tested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_4.2\"></a>\n",
    "## 4.2 &emsp; Apply the watermask to each tested point\n",
    "\n",
    "The watermask is applied by subtracting thewatermask from the CV reclassified raster \n",
    "\n",
    "        0-0 =     0     Non-crop\n",
    "        1-111 = -110    Water\n",
    "        1-0 =     1     Crop\n",
    "        0-111 = -111    Water\n",
    "        \n",
    "A watermask is necessary because the CV values for water is similar to that of an active crop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_4.3\"></a>\n",
    "## 4.3 &emsp; Create a binary crop/non-crop classification at each tested threshold\n",
    "\n",
    "Creating a binary crop/non-crop classification at each tested threshold.\n",
    "\n",
    "          1 = crop\n",
    "        -10 = noncrop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_4.4\"></a>\n",
    "## 4.4 &emsp; Determine false alarm and true positive rates\n",
    "\n",
    "Finding the correctly and incorrectly classified pixels from each classification.\n",
    "\n",
    "Subtracted the binary crop/non-crop classification from the correct binary crop/non-crop classification from the CDL.\n",
    "\n",
    "        0 - -10 = 10       non-crop correctly classified as non-crop\n",
    "        1 - 1 =   0        crop correctly classified as crop\n",
    "        0 - 1 =  -1        non-crop incorrectly classified as crop\n",
    "        1- -10 =  11       crop incorrectly classified as non-crop\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_4.5\"></a>\n",
    "## 4.5 &emsp; Calculate sensitivity and specifity\n",
    "\n",
    "Calculating sensitivity and specificity:\n",
    "\n",
    "True Positive (TP) = Crop correctly classified as crop\n",
    "\n",
    "False Positive (FP) = Crop incorrectly classified as non-crop\n",
    "\n",
    "True Negitive (TN) = Non-crop correctly classified as non-crop\n",
    "\n",
    "False Negative (FN) = Non-crop incorrectly classified as crop\n",
    "\n",
    "True Positive Rate (TPR) = Sensitivity\n",
    "\n",
    "False Positive Rate (FPR) = Specificity\n",
    "\n",
    "Sensitivity = TP / (TP + TN)\n",
    "\n",
    "Specificity = TN / (TN + FP)\n",
    "\n",
    "For use in the generation of a ROC curve (1 - Specificity) is plotted by Sensitivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_4.6\"></a>\n",
    "## 4.6 &emsp; Calculate the ROC Curve\n",
    "\n",
    "An array is set up in order to plot the full ROC curve that includes all of the thresholds and False Alarm/True Positive rates calculated so far.\n",
    "\n",
    "\n",
    "Currently only uses CV of HH polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reps = 100\n",
    "if which_pol== \"HH\":\n",
    "    CV= copy.deepcopy(CV_HH)\n",
    "    print('caculating the ROC curve based on thresholds from HH polarization CV')\n",
    "else:\n",
    "    CV= copy.deepcopy(CV_HV)\n",
    "    print('caculating the ROC curve based on thresholds from HV polarization CV')\n",
    "\n",
    "\n",
    "CV_reclass = np.zeros((reps,rows,cols))\n",
    "CV_reclass[:] = copy.deepcopy(CV)\n",
    "\n",
    "CV_water = np.zeros((reps,rows,cols))\n",
    "\n",
    "CV_crop_non = np.zeros((reps,rows,cols))\n",
    "CV_crop_non[:] = copy.deepcopy(CV_water)\n",
    "\n",
    "CDL_CV = np.zeros((reps,rows,cols))\n",
    "\n",
    "denom_sens = np.zeros((reps))\n",
    "sensitivity_y = np.zeros((reps))\n",
    "denom_spec = np.zeros((reps))\n",
    "specificity_x = np.zeros((reps))\n",
    "sub_specificity_x = np.zeros((reps))\n",
    "\n",
    "data55_tmp =[]\n",
    "# fpr_tmp = []\n",
    "# tpr_tmp = []\n",
    "data100_tmp = []\n",
    "\n",
    "for i in range(0,reps):\n",
    "    # print(i)\n",
    "    threshold = float(i/reps)\n",
    "    # Reclassify CV array to distingush crop from non-crop\n",
    "    CV_reclass[i][np.where(CV_reclass[i]>= threshold)] = 1\n",
    "    CV_reclass[i][np.where(CV_reclass[i]< threshold)] = 0\n",
    "    # Subtract water mask from the CV reclassified raster\n",
    "    CV_water[i] = np.subtract(CV_reclass[i], watermask)\n",
    "    \n",
    "    # Create a binary crop/non-crop classification at each tested threshold.\n",
    "    CV_crop_non[i] = np.copy(CV_water[i])\n",
    "    CV_crop_non[i][np.where(CV_crop_non[i]>0)] = 1\n",
    "    CV_crop_non[i][np.where(CV_crop_non[i]<=0)] = -10\n",
    "    #Subtracted the binary crop/non-crop classification from the correct binary crop/non-crop classification from the CDL.\n",
    "    CDL_CV[i] = np.subtract(CDL_binary, CV_crop_non[i])\n",
    "    \n",
    "    #Calculate sensitivity and specificity\n",
    "    denom_sens[i] = np.add(np.count_nonzero(CDL_CV[i] == 0), np.count_nonzero(CDL_CV[i] == 11))\n",
    "    sensitivity_y[i] = np.divide(np.count_nonzero(CDL_CV[i] == 0),denom_sens[i])\n",
    "    denom_spec[i] = np.add(np.count_nonzero(CDL_CV[i] == 10)- cdl111, np.count_nonzero(CDL_CV[i] == -1))\n",
    "    specificity_x[i] = np.divide(np.count_nonzero(CDL_CV[i] == 10)- cdl111,denom_spec[i])\n",
    "    sub_specificity_x[i] = np.subtract(1, specificity_x[i])\n",
    "  \n",
    "    # Build array of sub specificity and sensitivity\n",
    "    data55_tmp.append([sub_specificity_x[i], sensitivity_y[i]])\n",
    "    # fpr_tmp.append([sub_specificity_x[i]])\n",
    "    # tpr_tmp.append([sensitivity_y[i]])\n",
    "    data100_tmp.append([sub_specificity_x[i], sensitivity_y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr = np.array(sub_specificity_x).T\n",
    "tpr = np.array(sensitivity_y).T\n",
    "data55 = np.array(data55_tmp)\n",
    "data100 = np.array(data100_tmp)\n",
    "\n",
    "# np.array([sub_specificity_x]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_4.7\"></a>\n",
    "## 4.7 &emsp; Plot the ROC curve\n",
    "\n",
    "Make a plot of the ROC and indicate locations of various threshold landmarks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data55.T\n",
    "plt.plot(x, y, '-')\n",
    "plt.plot([0.0, 1.0], [0.0,1.0], linestyle= \"--\", color = \"red\")\n",
    "\n",
    "#arrows highlighting where each threshold value is\n",
    "\n",
    "plt.annotate('0.1 Threshold', xy=(sub_specificity_x[10], sensitivity_y[10]),arrowprops=dict(arrowstyle='->'), xytext=(0.87, 0.85)) \n",
    "plt.annotate('0.2 Threshold', xy=(sub_specificity_x[20], sensitivity_y[20]),arrowprops=dict(arrowstyle='->'), xytext=(0.75, 0.9)) \n",
    "plt.annotate('0.3 Threshold', xy=(sub_specificity_x[30], sensitivity_y[30]),arrowprops=dict(arrowstyle='->'), xytext=(0.4, 0.83)) \n",
    "plt.annotate('0.4 Threshold', xy=(sub_specificity_x[40], sensitivity_y[40]),arrowprops=dict(arrowstyle='->'), xytext=(0.05, 0.7)) \n",
    "plt.annotate('0.5 Threshold', xy=(sub_specificity_x[50], sensitivity_y[50]),arrowprops=dict(arrowstyle='->'), xytext=(0.2, 0.65)) \n",
    "plt.annotate('0.6 Threshold', xy=(sub_specificity_x[60], sensitivity_y[60]),arrowprops=dict(arrowstyle='->'), xytext=(0.2, 0.5)) \n",
    "plt.annotate('0.7 Threshold', xy=(sub_specificity_x[70], sensitivity_y[70]),arrowprops=dict(arrowstyle='->'), xytext=(0.25, 0.4)) \n",
    "plt.annotate('0.8 Threshold', xy=(sub_specificity_x[80], sensitivity_y[80]),arrowprops=dict(arrowstyle='->'), xytext=(0.3, 0.2)) \n",
    "plt.annotate('0.9 Threshold', xy=(sub_specificity_x[90], sensitivity_y[90]),arrowprops=dict(arrowstyle='->'), xytext=(0.1, 0.05)) \n",
    "\n",
    "#Setting up plot layout\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(-0.01, 1)\n",
    "plt.grid()\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.ylabel('True Positive Rate (sensitivity)', fontsize=12)\n",
    "plt.xlabel('False Positive Rate (1-specificity)', fontsize=12)\n",
    "plt.rcParams['figure.figsize'] = (20,5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_5\"></a>\n",
    "<a id=\"SEC_5.1\"></a>\n",
    "# 5 &emsp; Calculate optimal threshold and other performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 &emsp; Using Youden's Index to Find the Ideal Classification Threshold\n",
    "Youden's Index is the point on the ROC curve where sensitivity and specificity are maximized, a maximum difference between TPR and FPR (TPR - FPR). The threshold ranges between 0 and 1. A plot is generated to show the point on the curve where the Youden's Index point is on curve.\n",
    "\n",
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the inputs\n",
    "\n",
    "#100 different CV thresholds used \n",
    "# thresholds = [0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]\n",
    "# fpr = np.array([sub_specificity0_x, sub_specificity01_x, sub_specificity02_x, sub_specificity03_x, sub_specificity04_x, sub_specificity05_x, sub_specificity06_x, sub_specificity07_x, sub_specificity08_x, sub_specificity09_x, sub_specificity1_x, sub_specificity11_x, sub_specificity12_x, sub_specificity13_x, sub_specificity14_x, sub_specificity15_x, sub_specificity16_x, sub_specificity17_x, sub_specificity18_x, sub_specificity19_x, sub_specificity2_x, sub_specificity21_x, sub_specificity22_x, sub_specificity23_x, sub_specificity24_x, sub_specificity25_x, sub_specificity26_x, sub_specificity27_x, sub_specificity28_x, sub_specificity29_x, sub_specificity3_x, sub_specificity31_x, sub_specificity32_x, sub_specificity33_x, sub_specificity34_x, sub_specificity35_x, sub_specificity36_x, sub_specificity37_x, sub_specificity38_x, sub_specificity39_x, sub_specificity4_x, sub_specificity41_x, sub_specificity42_x, sub_specificity43_x, sub_specificity44_x, sub_specificity45_x, sub_specificity46_x, sub_specificity47_x, sub_specificity48_x, sub_specificity49_x, sub_specificity5_x, sub_specificity51_x, sub_specificity52_x, sub_specificity53_x, sub_specificity54_x, sub_specificity55_x, sub_specificity56_x, sub_specificity57_x, sub_specificity58_x, sub_specificity59_x, sub_specificity6_x, sub_specificity61_x, sub_specificity62_x, sub_specificity63_x, sub_specificity64_x, sub_specificity65_x, sub_specificity66_x, sub_specificity67_x, sub_specificity68_x, sub_specificity69_x, sub_specificity7_x, sub_specificity71_x, sub_specificity72_x, sub_specificity73_x, sub_specificity74_x, sub_specificity75_x, sub_specificity76_x, sub_specificity77_x, sub_specificity78_x, sub_specificity79_x, sub_specificity8_x, sub_specificity81_x, sub_specificity82_x, sub_specificity83_x, sub_specificity84_x, sub_specificity85_x, sub_specificity86_x, sub_specificity87_x, sub_specificity88_x, sub_specificity89_x, sub_specificity9_x, sub_specificity91_x, sub_specificity92_x, sub_specificity93_x, sub_specificity94_x, sub_specificity95_x, sub_specificity96_x, sub_specificity97_x, sub_specificity98_x, sub_specificity99_x])\n",
    "# tpr = np.array([sensitivity0_y, sensitivity01_y, sensitivity02_y, sensitivity03_y, sensitivity04_y, sensitivity05_y, sensitivity06_y, sensitivity07_y, sensitivity08_y, sensitivity09_y, sensitivity1_y, sensitivity11_y, sensitivity12_y, sensitivity13_y, sensitivity14_y, sensitivity15_y, sensitivity16_y, sensitivity17_y, sensitivity18_y, sensitivity19_y, sensitivity2_y, sensitivity21_y, sensitivity22_y, sensitivity23_y, sensitivity24_y, sensitivity25_y, sensitivity26_y, sensitivity27_y, sensitivity28_y, sensitivity29_y, sensitivity3_y, sensitivity31_y, sensitivity32_y, sensitivity33_y, sensitivity34_y, sensitivity35_y, sensitivity36_y, sensitivity37_y, sensitivity38_y, sensitivity39_y, sensitivity4_y, sensitivity41_y, sensitivity42_y, sensitivity43_y, sensitivity44_y, sensitivity45_y, sensitivity46_y, sensitivity47_y, sensitivity48_y, sensitivity49_y, sensitivity5_y, sensitivity51_y, sensitivity52_y, sensitivity53_y, sensitivity54_y, sensitivity55_y, sensitivity56_y, sensitivity57_y, sensitivity58_y, sensitivity59_y, sensitivity6_y, sensitivity61_y, sensitivity62_y, sensitivity63_y, sensitivity64_y, sensitivity65_y, sensitivity66_y, sensitivity67_y, sensitivity68_y, sensitivity69_y, sensitivity7_y, sensitivity71_y, sensitivity72_y, sensitivity73_y, sensitivity74_y, sensitivity75_y, sensitivity76_y, sensitivity77_y, sensitivity78_y, sensitivity79_y, sensitivity8_y, sensitivity81_y, sensitivity82_y, sensitivity83_y, sensitivity84_y, sensitivity85_y, sensitivity86_y, sensitivity87_y, sensitivity88_y, sensitivity89_y, sensitivity9_y, sensitivity91_y, sensitivity92_y, sensitivity93_y, sensitivity94_y, sensitivity95_y, sensitivity96_y, sensitivity97_y, sensitivity98_y, sensitivity99_y])\n",
    "\n",
    "thresholds= list(np.linspace(0,99,100) /100)\n",
    "\n",
    "\n",
    "#finding the threshold value with the greatest difference between TPR and FPR (x and y axes)\n",
    "def cutoff_youdens_j(fpr,tpr,thresholds):\n",
    "    j_scores = tpr-fpr\n",
    "    j_ordered = sorted(zip(j_scores,thresholds))\n",
    "    return j_ordered[-1][1]\n",
    "\n",
    "best_thresh = cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "print (\"The best threshold from Youden's Index: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displays Youden's Index calculated point on cure \n",
    "\n",
    "best_thresh_index = np.where(thresholds==best_thresh)\n",
    "fpr_specificity_ideal = fpr[best_thresh_index][0]\n",
    "tpr_sensitivity_ideal = tpr[best_thresh_index][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_5.2\"></a>\n",
    "## 5.2 &emsp; Display Youden's Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data100.T\n",
    "plt.scatter(x, y)\n",
    "plt.plot([0.0, 1.0], [0.0,1.0], linestyle= \"--\", color = \"red\")\n",
    "plt.plot([fpr_specificity_ideal], [tpr_sensitivity_ideal], marker='o', markersize=8, color=\"red\")\n",
    "\n",
    "#arrows highlighting where each threshold value is\n",
    "plt.annotate('0.1 Threshold', xy=(sub_specificity_x[10], sensitivity_y[10]),arrowprops=dict(arrowstyle='->'), xytext=(0.87, 0.85)) \n",
    "plt.annotate('0.2 Threshold', xy=(sub_specificity_x[20], sensitivity_y[20]),arrowprops=dict(arrowstyle='->'), xytext=(0.75, 0.9)) \n",
    "plt.annotate('0.3 Threshold', xy=(sub_specificity_x[30], sensitivity_y[30]),arrowprops=dict(arrowstyle='->'), xytext=(0.4, 0.83)) \n",
    "plt.annotate('0.4 Threshold', xy=(sub_specificity_x[40], sensitivity_y[40]),arrowprops=dict(arrowstyle='->'), xytext=(0.05, 0.7)) \n",
    "plt.annotate('0.5 Threshold', xy=(sub_specificity_x[50], sensitivity_y[50]),arrowprops=dict(arrowstyle='->'), xytext=(0.2, 0.65)) \n",
    "plt.annotate('0.6 Threshold', xy=(sub_specificity_x[60], sensitivity_y[60]),arrowprops=dict(arrowstyle='->'), xytext=(0.2, 0.5)) \n",
    "plt.annotate('0.7 Threshold', xy=(sub_specificity_x[70], sensitivity_y[70]),arrowprops=dict(arrowstyle='->'), xytext=(0.25, 0.4)) \n",
    "plt.annotate('0.8 Threshold', xy=(sub_specificity_x[80], sensitivity_y[80]),arrowprops=dict(arrowstyle='->'), xytext=(0.3, 0.2)) \n",
    "plt.annotate('0.9 Threshold', xy=(sub_specificity_x[90], sensitivity_y[90]),arrowprops=dict(arrowstyle='->'), xytext=(0.1, 0.05)) \n",
    "\n",
    "#Setting plot layout\n",
    "plt.grid()\n",
    "plt.title('Reciever Operating Characteristic')\n",
    "plt.ylabel('True Positive Rate (sensitivity)', fontsize=12)\n",
    "plt.xlabel('False Positive Rate (1-specificity)', fontsize=12)\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_5.3\"></a>\n",
    "## 5.3 &emsp; Find the AUC\n",
    "\n",
    "Area Under the ROC curve (AUC) is a performance measurement (between 0 and 1) describing the discrimination power between the crop and non-crop classes. The higher the AUC value the better the model is at separating the two classes. An AUC value of 0.5 signifies there is no distinguishability between the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC = (round(sklearn.metrics.auc(fpr, tpr, reorder= 'deprecated'), 2))\n",
    "AUC = round(sklearn.metrics.auc(fpr, tpr), 2)\n",
    "\n",
    "print (\"Area Under Curve (AUC):\", AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_5.4\"></a>\n",
    "## 5.4 &emsp; Getting Accuracy Statictics for the Youden's Index Optimal Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a crop/non-crop classification based on the Youden's Index optimal threshold\n",
    "2. Return the J-statistic for the determined threshold (maximum difference value between TPR and FPR ranging between 0 and 1)\n",
    "3. Get percent crop and non-crop classified correctly and incorrectly\n",
    "4. Get User's and Producer's accuracy of the classification for both crop and non-crop classes\n",
    "5. Calculate the Kapppa Coefficient = the measure of the agreement between the SAR imagery derived classification and the CDL\n",
    "    Kappa = (total pixel x total correct pixel - sum of the products)/(total pixel^2 - sum of products)\n",
    "    Sum of products = sum of row total x column total \n",
    "        Interpreting Kappa Statistic: \n",
    "         < 0.20          = Poor agreement \n",
    "         0.20 - 0.40     = Fair agreement \n",
    "         0.40 - 0.60     = Moderate agreement \n",
    "         0.60 - 0.80     = Good agreement \n",
    "         0.80 - 1.00     = Very good agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify image using the Youden's Index Optimal Threshold\n",
    "CV_reclass_ideal = np.copy(CV)\n",
    "CV_reclass_ideal[np.where(CV_reclass_ideal>= best_thresh)] = 1\n",
    "CV_reclass_ideal[np.where(CV_reclass_ideal< best_thresh)] = 0\n",
    "CVideal_water = np.subtract(CV_reclass_ideal, watermask)\n",
    "CVideal_crop_non = np.copy(CVideal_water)\n",
    "CVideal_crop_non[np.where(CVideal_crop_non>0)] = 1\n",
    "CVideal_crop_non[np.where(CVideal_crop_non<=0)] = -10\n",
    "CDL_CVideal = np.subtract(CDL_binary, CVideal_crop_non)\n",
    "\n",
    "#Determining the J-statistic calculated by finding the maximum difference between the TPR and FPR\n",
    "j_scores = tpr-fpr\n",
    "j_ordered = sorted(zip(j_scores,thresholds))\n",
    "j_statistic = (np.round(j_ordered[-1][0], 2))\n",
    "\n",
    "#Getting statistics on the accuracy of the CV classification using Youden's Index optimal threshold based on CDL classifications\n",
    "print ('Statistics of accuracy of using CV to classify crop vs non-crop based on CDL:')\n",
    "p_crop_correct = np.count_nonzero(CDL_CVideal == 0)/(cdl0)\n",
    "p_crop_correct1 = (round((p_crop_correct*100), 2))\n",
    "print ('% correct crop: ',p_crop_correct1)\n",
    "p_non_correct = (np.count_nonzero(CDL_CVideal == 10)-cdl111)/(cdl0)\n",
    "p_non_correct1 = (round((p_non_correct)*100, 2))\n",
    "print ('% correct non-crop: ', p_non_correct1)\n",
    "p_crop_incorrect = np.count_nonzero(CDL_CVideal == 11)/(cdl0)\n",
    "p_crop_incorrect1 = (round((p_crop_incorrect)*100, 2))  \n",
    "print ('% incorrect crop: ', p_crop_incorrect1)\n",
    "p_non_incorrect = np.count_nonzero(CDL_CVideal == -1)/(cdl0)\n",
    "p_non_incorrect1 = (round((p_non_incorrect)*100, 2))    \n",
    "print ('% incorrect non-crop: ', p_non_incorrect1)\n",
    "\n",
    "#Getting Overall Accuracy statistics of the CV classification using Youden's Index optimal threshold based on CDL classifications\n",
    "print ('\\nStatistics of overall accuracy of using CV to classify crop vs non-crop based on CDL')\n",
    "p_overall_correct = round((p_crop_correct + p_non_correct)*100, 2)\n",
    "print ('% overall correct: ', p_overall_correct)\n",
    "p_overall_incorrect = round((p_crop_incorrect + p_non_incorrect)*100, 2)\n",
    "print ('% overall incorrect: ', p_overall_incorrect)\n",
    "\n",
    "#Getting user's and producer's accuracy of the CV classification based on CDL classifications\n",
    "print ('\\nUsers and producers accuracy statistics:')\n",
    "crop_correct = np.count_nonzero(CDL_CVideal == 0)\n",
    "non_correct = np.count_nonzero(CDL_CVideal == 10)\n",
    "crop_incorrect = np.count_nonzero(CDL_CVideal == 11)\n",
    "non_incorrect = np.count_nonzero(CDL_CVideal == -1)\n",
    "\n",
    "crop_producers_total = crop_correct + crop_incorrect\n",
    "non_producers_total = (non_correct - cdl111) + non_incorrect\n",
    "\n",
    "crop_users_total = crop_correct + non_incorrect\n",
    "non_users_total = (non_correct - cdl111) + crop_incorrect\n",
    "\n",
    "crop_p_accuracy = round((crop_correct/crop_producers_total)*100, 2)\n",
    "print ('% crop producers accuracy: ', crop_p_accuracy)\n",
    "non_p_accuracy = round(((non_correct - cdl111)/non_producers_total)*100, 2)\n",
    "print('% non-crop producers accuracy: ', non_p_accuracy)\n",
    "\n",
    "crop_u_accuracy = round((crop_correct/crop_users_total)*100, 2)\n",
    "print ('% crop users accuracy: ', crop_u_accuracy)\n",
    "non_u_accuracy = round(((non_correct - cdl111)/non_users_total)*100, 2)\n",
    "print ('% non-crop users accuracy: ', non_u_accuracy)\n",
    "\n",
    "#Calculating Kappa Coefficient\n",
    "Total_correct = np.count_nonzero(CDL_CVideal == 0) + (np.count_nonzero(CDL_CVideal == 10) - cdl111)\n",
    "\n",
    "Total_pixel_count = (cdl0)\n",
    "\n",
    "Sum_of_products_crop_row = np.count_nonzero(CDL_CVideal == 0) + np.count_nonzero(CDL_CVideal == -1)\n",
    "Sum_of_products_non_row = (np.count_nonzero(CDL_CVideal == 10) - cdl111) + np.count_nonzero(CDL_CVideal == 11)\n",
    "Sum_of_products_crop_col = np.count_nonzero(CDL_CVideal == 0) + np.count_nonzero(CDL_CVideal == 11)\n",
    "Sum_of_products_non_col = (np.count_nonzero(CDL_CVideal == 10) - cdl111) + np.count_nonzero(CDL_CVideal == -1)\n",
    "\n",
    "Sum_of_products = (Sum_of_products_crop_row * Sum_of_products_crop_col) + (Sum_of_products_non_row * Sum_of_products_non_col)\n",
    "\n",
    "Kappa_coefficient = round((Total_pixel_count * Total_correct - Sum_of_products) / (Total_pixel_count * Total_pixel_count - Sum_of_products), 2)\n",
    "print ('\\nKappa Coefficient: ', Kappa_coefficient)\n",
    "\n",
    "if Kappa_coefficient <= 0.2:\n",
    "    print ('Poor agreement')\n",
    "else:\n",
    "    if Kappa_coefficient <= 0.4:\n",
    "        print ('Fair agreement')\n",
    "    else:\n",
    "        if Kappa_coefficient <= 0.6:\n",
    "            print ('Moderate agreement')\n",
    "        else: \n",
    "            if Kappa_coefficient <= 0.8:\n",
    "                print ('Good agreement')\n",
    "            else: \n",
    "                if Kappa_coefficient > 0.8:\n",
    "                    print ('Very good agreement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_5.5\"></a>\n",
    "## 5.5 &emsp; Export Accuracy Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes the calculated accuracy results to an excel CSV file to the set output directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_classification_binary = \"NISAR_L3_CropAreaClassification.tif\" ##\"CV_classification_final.tif\"\n",
    "CV_classification_filename_with_accuracy = \"CV_classification_with_accuracy.tif\"\n",
    "Accuracy_results = \"NISAR_L3_CropAreaClassification_accuracy_statistics.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting accuracy statistics as a CSV file\n",
    "\n",
    "l0 = [best_thresh]\n",
    "l1 = [p_overall_correct]\n",
    "l2 = [p_crop_correct1]\n",
    "l3 = [p_non_correct1]\n",
    "l4 = [p_crop_incorrect1]\n",
    "l5 = [p_non_incorrect1]\n",
    "l6 = [crop_p_accuracy]\n",
    "l7 = [non_p_accuracy]\n",
    "l8 = [crop_u_accuracy]\n",
    "l9 = [non_u_accuracy]\n",
    "l10 = [Kappa_coefficient]\n",
    "l11 = [j_statistic]\n",
    "l12 = [AUC]\n",
    "\n",
    "df = pd.DataFrame({\"Threshold\": l0, \"Overall Correct\": l1, \"% crop correct\": l2, \"% non-crop correct\": l3, \"% crop incorrect\": l4, \"% non-crop incorrect\": l5, \"% Crop Producers Accuracy\": l6, \"% Non-crop Producers Accuarcy\": l7, \"% Crop Users Accuracy\":l8, \"% Non-crop Users Accuracy\": l9, \"Kappa Coefficient\": l10, \"J-statistic\": l11, \"AUC\": l12})\n",
    "\n",
    "df.to_csv(str(aoi_dir / Accuracy_results))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)<br>\n",
    "[previous section](#SEC_4.4)<br>\n",
    "[next section](#SEC_4.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_5.6\"></a>\n",
    "## 5.6 &emsp; Export the classified image as 20m, downsample to 1 Ha resolution and export final L3 classification product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes the array to a geotiff that is classified by the Youden's Index ideal threshold based on CV to the set output directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today= datetime.date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "classified_20m_prefix= \"%s_%s_%s_20m_classification.tif\" %(aoi, which_pol, today)\n",
    "L3_ha_prefix= \"NISAR_L3_CROPAREA_%s_%s_%s_classification.tif\" %(aoi, which_pol, today)\n",
    "\n",
    "print(classified_20m_prefix)\n",
    "print(L3_ha_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define write_geotiff function - writes an array to a geotiff\n",
    "def write_geotiff_export(image, geotrans, cols, rows, spatial_ref, nodata, outfilename):    \n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(outfilename, cols, rows, 1, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform(geotrans)\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(image)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outband.SetNoDataValue(np.nan)\n",
    "    outRasterSRS.ImportFromWkt(spatial_ref)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "        \n",
    "write_geotiff_export(CV_reclass_ideal, geotransform, cols, rows, spatialref, np.nan, str(aoi_dir / classified_20m_prefix))\n",
    "\n",
    "plt.imshow(CV_reclass_ideal,interpolation='nearest',cmap='Reds_r');\n",
    "plt.colorbar(fraction=0.046*CV_reclass_ideal.shape[0]/CV_reclass_ideal.shape[1],pad=0.04);\n",
    "plt.title('Classified Crop/Non-Crop Area (20m resolution) ');\n",
    "print('Crop pixels marked in white (Crop=1, Non-Crop=0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsample to the hectare scale for generation of the final L3 crop area product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_20m_files= sorted(glob.glob(str(aoi_dir / classified_20m_prefix)))\n",
    "for file in classified_20m_files:\n",
    "    file_name= str(file)\n",
    "    classified_20m_file= gdal.Open(file_name)\n",
    "    print(file_name)\n",
    "gdal.UseExceptions()\n",
    "\n",
    "gdal.Warp(str(aoi_dir/L3_ha_prefix), classified_20m_file, xRes= 100, yRes= 100, resampleAlg='near', format= 'COG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3_product_file= glob.glob(str(aoi_dir/L3_ha_prefix))\n",
    "for file in L3_product_file:\n",
    "    L3_product= str(file)\n",
    "    croparea_L3_classification= gdal.Open(L3_product).ReadAsArray()\n",
    "\n",
    "plt.imshow(croparea_L3_classification, interpolation='nearest', cmap='Reds_r');\n",
    "plt.title('Classified Crop/Non-Crop Area (1 Ha resolution)')\n",
    "plt.colorbar(fraction=0.046*croparea_L3_classification.shape[0]/croparea_L3_classification.shape[1],pad=0.04);\n",
    "print('Crop pixels marked in white (Crop=1, Non-Crop=0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SEC_6\"></a>\n",
    "# 6 &emsp; References\n",
    "The references listed below can be found in the subdirectory \"References\" listed as part of this Jupyter notebook.\n",
    "\n",
    "\n",
    "1.\tWhelen, T. and P. Siqueira, A Multi-season Study of L-band UAVSAR Observations for Agricultural Fields in the San Joaquin Valley, Rem. Sens. Env., 193, 216-224, https://doi.org/10.1016/j.rse.2017.03.014, 2017.\n",
    "\n",
    "2.\tWhelen, T. and P. Siqueira, Time-series agricultural classification of Sentinel-1 data over North Dakota, Rem. Sens. Lett., 9(5), 411-420, https://doi.org/10.1080/2150704X.2018.1430393, 2018.\n",
    "\n",
    "3.\tWhelen, T. and P. Siqueira, Coefficient of variation for use in crop area classification across multiple climates, Int. J. Appl. Earth. Obs. & Geoinf., 67, 114-122, https://doi.org/10.1016/j.jag.2017.12.014, 2018.\n",
    "\n",
    "4.\tKraatz, S., N. Torbick, X. Jiao, X. Huang, L.D. Robertson, A. Davidson, H. McNairn, M.H. Cosh, P. Siqueira, Comparison between Dense L-Band and C-Band Synthetic Aperture Radar (SAR) Time Series for Crop Area Mapping over a NISAR Calibration-Validation Site, Agronomy. 11(2), https://doi.org/10.3390/agronomy11020273, 2021.\n",
    "\n",
    "5.\tKraatz, S., S. Rose, M. Cosh, N. Torbick, X. Huang, & P. Siqueira, Performance evaluation of UAVSAR and simulated NISAR data for crop/noncrop classification over Stoneville, MS. Earth and Space Sci, 8(1), e2020EA001363. https://doi.org/10.1029/2020EA001363, 2021\n",
    "\n",
    "6.\tRose, S., S. Kraatz, J. Kellndorfer, M.H. Cosh, N. Torbick, X. Huang, and P. Siqueira, Evaluating NISAR's cropland mapping algorithm over the conterminous United States using Sentinel-1 data, Rem. Sens. Env., 260, 112472, https://doi.org/10.1016/j.rse.2021.112472, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to TOP](#TOP)<br>\n",
    "[back to TOC](#TOC)<br>\n",
    "[previous section](#SEC_4.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
